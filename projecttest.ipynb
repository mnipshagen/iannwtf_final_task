{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Model - Group 9 <div style=\"text-align: right; float: right\"> IANNWTF - Sheet08 </div>\n",
    "In this sheet we used a generative model on the MNIST data set to generate \"fake\" handwritten numbers.\n",
    "\n",
    "The training process is saved as summaries and saved in the `summary_dir` directory (it's called summary...). In tensorboard you can find the graphs for the losses, and can look at the images over the course of training. So please execute code to access graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:29:00.549741Z",
     "start_time": "2018-01-19T13:28:53.844802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonia/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct, os, time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lukas' helper script for loading the mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:29:00.610904Z",
     "start_time": "2018-01-19T13:29:00.550745Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load 08_mnist-gan-helper.py\n",
    "class MNIST_GAN():\n",
    "    def __init__(self, directory):\n",
    "        self._directory = directory\n",
    "        \n",
    "        self._data = self._load_binaries(\"train-images.idx3-ubyte\")\n",
    "        self._data = np.append(self._data, self._load_binaries(\"t10k-images.idx3-ubyte\"), axis = 0)\n",
    "        self._data = ((self._data / 255) * 2) - 1\n",
    "        self._data = self._data.reshape([-1, 28, 28, 1])\n",
    "\n",
    "    \n",
    "    def _load_binaries(self, file_name):\n",
    "        path = os.path.join(self._directory, file_name)\n",
    "        \n",
    "        with open(path, 'rb') as fd:\n",
    "            check, items_n = struct.unpack(\">ii\", fd.read(8))\n",
    "\n",
    "            if \"images\" in file_name and check == 2051:\n",
    "                height, width = struct.unpack(\">II\", fd.read(8))\n",
    "                images = np.fromfile(fd, dtype = 'uint8')\n",
    "                return np.reshape(images, (items_n, height, width))\n",
    "            else:\n",
    "                raise ValueError(\"Not a MNIST file: \" + path)\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        samples_n = self._data.shape[0]\n",
    "        if batch_size <= 0:\n",
    "            batch_size = samples_n\n",
    "            \n",
    "        random_indices = np.random.choice(samples_n, samples_n, replace = False)\n",
    "        data = self._data[random_indices]\n",
    "        \n",
    "        for i in range(samples_n // batch_size):\n",
    "            on = i * batch_size\n",
    "            off = on + batch_size\n",
    "            yield data[on:off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lukas' layer helper file\n",
    "The `back_conv_layer` was implemented by us. It is mostly analogue to the `conv_layer` function, with the biggest difference being the `target_shape` parameter, which holds the output shape to be genereated by the transposed convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:29:01.018078Z",
     "start_time": "2018-01-19T13:29:00.613913Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load 08_mnist-gan-layers.py\n",
    "def feed_forward_layer(x, target_size, normalize = False, activation_function = None):\n",
    "    print(\"Forward-Layer:\" + str(x.shape))\n",
    "    \n",
    "    fan_in = int(x.shape[-1])\n",
    "    \n",
    "    if activation_function == tf.nn.relu:\n",
    "        var_init = tf.random_normal_initializer(stddev = 2/fan_in)\n",
    "    else:\n",
    "        var_init = tf.random_normal_initializer(stddev = fan_in**(-1/2))\n",
    "    weights = tf.get_variable(\"weights\", [x.shape[1], target_size], tf.float32, var_init)\n",
    "    \n",
    "    var_init = tf.constant_initializer(0.0)\n",
    "    biases = tf.get_variable(\"biases\", [target_size], tf.float32, var_init)\n",
    "    \n",
    "    activation = tf.matmul(x, weights) + biases\n",
    "    \n",
    "    if normalize:\n",
    "        activation = batch_norm(activation, [0])\n",
    "    \n",
    "    return activation_function(activation) if callable(activation_function) else activation\n",
    "\n",
    "\n",
    "def conv_layer(x, kernel_quantity, kernel_size, stride_size, normalize = False, activation_function = False):\n",
    "    print(\"Conv-Layer:\" + str(x.shape))\n",
    "    depth = x.shape[-1]\n",
    "    fan_in = int(x.shape[1] * x.shape[2])\n",
    "    \n",
    "    if activation_function == tf.nn.relu or activation_function == tf.nn.leaky_relu:\n",
    "        var_init = tf.random_normal_initializer(stddev = 2/fan_in)\n",
    "    else:\n",
    "        var_init = tf.random_normal_initializer(stddev = fan_in**(-1/2))\n",
    "    kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, depth, kernel_quantity], tf.float32, var_init)\n",
    "    \n",
    "    var_init = tf.constant_initializer(0.0)\n",
    "    biases = tf.get_variable(\"biases\", [kernel_quantity], initializer = var_init)\n",
    "    \n",
    "    activation = tf.nn.conv2d(x, kernels, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "    \n",
    "    if normalize:\n",
    "        activation = batch_norm(activation, [0, 1, 2])\n",
    "    \n",
    "    return activation_function(activation) if callable(activation_function) else activation\n",
    "\n",
    "\n",
    "def back_conv_layer(x, target_shape, kernel_size, stride_size, normalize = False, activation_function = False):\n",
    "    print(\"De-Conv-Layer:\" + str(x.shape))\n",
    "    depth = x.shape[-1]                   #number of activation maps in the de_conv layer (in_channels)\n",
    "    fan_in = int(x.shape[1] * x.shape[2]) #resolution of the activation map, important for proper intitialization of kernel weights\n",
    "    kernel_quantity = target_shape[-1]    #number of activation maps in the target layer (out_channel)\n",
    "    \n",
    "    if activation_function == tf.nn.relu or activation_function == tf.nn.leaky_relu:\n",
    "        var_init = tf.random_normal_initializer(stddev = 2/fan_in)\n",
    "    else:\n",
    "        var_init = tf.random_normal_initializer(stddev = fan_in**(-1/2))\n",
    "        \n",
    "    # switch kernel_quantity and depth (in_channels and out_channels) because we do deconvolution\n",
    "    kernels = tf.get_variable(\"kernels\", [kernel_size, kernel_size, kernel_quantity, depth], tf.float32, var_init)\n",
    "    \n",
    "    var_init = tf.constant_initializer(0.0)\n",
    "    biases = tf.get_variable(\"biases\", [kernel_quantity], initializer = var_init)\n",
    "    \n",
    "    # use conv2d_transpose as instructed\n",
    "    activation = tf.nn.conv2d_transpose(x, kernels, target_shape, strides = [1, stride_size, stride_size, 1], padding = \"SAME\") + biases\n",
    "    \n",
    "    if normalize:\n",
    "        activation = batch_norm(activation, [0, 1, 2])\n",
    "    \n",
    "    return activation_function(activation) if callable(activation_function) else activation\n",
    "\n",
    "def flatten(x):\n",
    "    size = int(np.prod(x.shape[1:]))\n",
    "    return tf.reshape(x, [-1, size])\n",
    "\n",
    "def _pop_batch_norm(x, pop_mean, pop_var, offset, scale):\n",
    "    return tf.nn.batch_normalization(x, pop_mean, pop_var, offset, scale, 1e-6)\n",
    "\n",
    "def _batch_norm(x, pop_mean, pop_var, mean, var, offset, scale):\n",
    "    decay = 0.99\n",
    "    \n",
    "    dependency_1 = tf.assign(pop_mean, pop_mean * decay + mean * (1 - decay))\n",
    "    dependency_2 = tf.assign(pop_var, pop_var * decay + var * (1 - decay))\n",
    "\n",
    "    with tf.control_dependencies([dependency_1, dependency_2]):\n",
    "        return tf.nn.batch_normalization(x, mean, var, offset, scale, 1e-6)\n",
    "\n",
    "def batch_norm(x, axes):\n",
    "    depth = x.shape[-1]\n",
    "    mean, var = tf.nn.moments(x, axes = axes)\n",
    "    global is_training\n",
    "    \n",
    "    var_init = tf.constant_initializer(0.0)\n",
    "    offset = tf.get_variable(\"offset\", [depth], tf.float32, var_init)\n",
    "    var_init = tf.constant_initializer(1.0)\n",
    "    scale = tf.get_variable(\"scale\", [depth], tf.float32, var_init)\n",
    "    \n",
    "    pop_mean = tf.get_variable(\"pop_mean\", [depth], initializer = tf.zeros_initializer(), trainable = False)\n",
    "    pop_var = tf.get_variable(\"pop_var\", [depth], initializer = tf.ones_initializer(), trainable = False)\n",
    "    \n",
    "    return tf.cond(\n",
    "        is_training,\n",
    "        lambda: _batch_norm(x, pop_mean, pop_var, mean, var, offset, scale),\n",
    "        lambda: _pop_batch_norm(x, pop_mean, pop_var, offset, scale)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the MNIST data and hyperparameters\n",
    "`batch_size` is used for the fake and the real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mnist = MNIST_GAN(\"\")\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "learning_rate = 0.0004\n",
    "beta1 = 0.5\n",
    "\n",
    "#gen_feature_maps = [64, 32, 16] # target shapes for generator layers\n",
    "\n",
    "# for tensorboard\n",
    "weight_dir = \"weights/\"\n",
    "summary_dir = \"summary/\"\n",
    "\n",
    "## Hyperparameters\n",
    "embedding_size = 64\n",
    "lstm_memory_size = 64\n",
    "ingredient_amount = 20000 # however many there are\n",
    "cutoff_length = 300\n",
    "subsequence_length = 300\n",
    "batch_size = 250\n",
    "epochs = 6\n",
    "learning_rate = 0.05\n",
    "dropout_rate = 0.85\n",
    "optimizer = tf.train.AdamOptimizer\n",
    "layer1_size = 512\n",
    "layer2_size = 64\n",
    "layer_out_size = 1\n",
    "\n",
    "\n",
    "z_size = 50 # length of random input vector\n",
    "max_ingredients = 15\n",
    "\n",
    "starter_learning_rate = 0.05\n",
    "\n",
    "dis_feature_maps = [ 8, 16, 32] # target shapes for discriminator layers. maybe to be changed? dunno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ings(embeddings, ingredients):\n",
    "    '''\n",
    "    embeddings: the weight matrix with all ingredients representations shape: [ingredient_amount, lstm_memory_size]\n",
    "    ingredients: a matrix of ingedient vectors of who we want to find the nearest neigbhours\n",
    "      \n",
    "    '''''\n",
    "    normed_embedding = tf.nn.l2_normalize(embeddings, dim=1)\n",
    "    if (type(ingredients)!= list):\n",
    "        arrays = ingredients\n",
    "    #else: # we shouldn't have IDs, delete later\n",
    "     #   ingredients = np.array(ingredients)\n",
    "      #  arrays = tf.nn.embedding_lookup(embeddings, ingredients)\n",
    "    \n",
    "    # initalize \"recipes\". not sure yet how or if the loop thing is even the optimal way to do it\n",
    "    \n",
    "    recipes = []\n",
    "    \n",
    "    arraylist = tf.unstack(arrays)\n",
    "    \n",
    "    for array in arraylist : # get each recipe (sample in batch_size)\n",
    "        \n",
    "        normed_array = tf.nn.l2_normalize(array, dim=1) # what is this for?\n",
    "\n",
    "        cosine_similarity = tf.matmul(normed_array, tf.transpose(normed_embedding, [1, 0]))\n",
    "        \n",
    "        closest_ings = tf.argmax(cosine_similarity, 1)  # shape [max_ingredients], type int64. we only need 1 ingredient, so no need for top_k anymore\n",
    "        \n",
    "        # stack this on top of recipes so we get batch_size, max_ingredients as output size in the end.\n",
    "        # todo: actually implement.\n",
    "        recipes = recipes + [closest_ings]\n",
    "    \n",
    "    recipes = tf.stack(recipes)\n",
    "    return recipes # returns index of closest ingredient. let's hope the dimension stuff works out in this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:50:56.003809Z",
     "start_time": "2018-01-19T13:50:52.296820Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Tensor' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e473a9097c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#orig_recipes = batch_norm(tf.placeholder(tf.int64, [batch_size,max_ingredients]), [0,1,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0morig_recipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_ingredients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-aa98ebff4c84>\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(x, axes)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_pop_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 instructions)\n\u001b[0;32m--> 316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    318\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[0mcontext_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m     \u001b[0morig_res_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_res_t\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true_fn must have a return value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1723\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m     \u001b[0moriginal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-aa98ebff4c84>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     return tf.cond(\n\u001b[1;32m    101\u001b[0m         \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_pop_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-5-aa98ebff4c84>\u001b[0m in \u001b[0;36m_batch_norm\u001b[0;34m(x, pop_mean, pop_var, mean, var, offset, scale)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mdependency_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_mean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mdependency_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_var\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Tensor' and 'float'"
     ]
    }
   ],
   "source": [
    "# Defining the graph\n",
    "tf.reset_default_graph()\n",
    "   \n",
    "###### The generator network. ######      \n",
    "with tf.variable_scope(\"generator\"):\n",
    "  \n",
    "    # see homework for original gen network\n",
    "\n",
    "    ## placeholders\n",
    "    with tf.variable_scope(\"inputs\"):\n",
    "        input_vec = tf.placeholder(tf.float32,[batch_size,z_size]) # for random input\n",
    "        is_training = tf.placeholder(tf.bool, [])\n",
    "        \n",
    "        # what do the dimensions of this denote again?\n",
    "        # i put *max_ingredients so it doesn't crash. like where I created the BasicLSTMCell a couple of lines later. how many \"units\" does it need?\n",
    "        cell_state = tf.placeholder(tf.float32,[batch_size, lstm_memory_size*max_ingredients],name=\"cell_state\")\n",
    "        hidden_state = tf.placeholder(tf.float32,[batch_size, lstm_memory_size*max_ingredients],name=\"hidden_state\")\n",
    "        \n",
    "        # original recipe placeholder. should be batch_size, max_ingredients, 3 later but for now we'll only take ingreidnets\n",
    "        #orig_recipes = batch_norm(tf.placeholder(tf.int64, [batch_size,max_ingredients]), [0,1,2])\n",
    "\n",
    "        orig_recipes = batch_norm(tf.placeholder(tf.int64, [batch_size,max_ingredients]), [0,1])\n",
    "\n",
    "\n",
    "    ##### rnn\n",
    "    with tf.variable_scope(\"rnn\"):\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(lstm_memory_size*max_ingredients)\n",
    "        cell= tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout_rate)\n",
    "        zero_state = cell.zero_state(batch_size, tf.float32)\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c = cell_state, h = hidden_state) # should be fine so far? no changes needed?\n",
    "        \n",
    "        outputs, state = tf.nn.static_rnn(cell, [input_vec], initial_state = state)\n",
    "        \n",
    "        # so at least in the example, lstm_memory_size == embedding_size.\n",
    "        # so what do we do about the subsequence length?\n",
    "        # for now I'll just ignore since we haven't even used sequences but the input_vec only. veeeery unsure about\n",
    "        # this though.\n",
    "        # so here I will state what the output should look like but not sure how we get the LSTM to produce this exact amount of data\n",
    "        outputs = tf.reshape(tf.concat(outputs, axis=1), [batch_size, max_ingredients, lstm_memory_size])\n",
    "\n",
    "\n",
    "    ##### embedding\n",
    "    with tf.variable_scope(\"embedding\"):\n",
    "        init = tf.random_uniform_initializer(-1.0,1.0)\n",
    "        embeddings = tf.get_variable(\"embedding\", [ingredient_amount, embedding_size], initializer=init)\n",
    "\n",
    "\n",
    "        ##fake_recipes will have dimension batch_size*max_ingredients*3 just like the original ones (for now without 3)             \n",
    "        # so get_ings will have to return batch_size*max_ingredients for now.\n",
    "        # might or might not work at the current state :D\n",
    "        fake_recipes = get_ings(embeddings,outputs) \n",
    "        \n",
    "        \n",
    "    train_gen = tf.get_variable_scope().get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "\n",
    "# create input batch for discriminator\n",
    "batch = tf.concat([fake_recipes, orig_recipes],axis=0)\n",
    "\n",
    "##### The discriminator network #####\n",
    "# does this need to be adapted according to new data shape?\n",
    "# i mean, we probably cannot convolve it this easily right? does convolution even make that much sense here?\n",
    "train_dis = []\n",
    "with tf.variable_scope(\"discriminator\"):\n",
    "    with tf.variable_scope(\"layer1\"):\n",
    "        fm = dis_feature_maps[0]\n",
    "        conv1 = conv_layer(batch,fm,5,2,True,tf.nn.leaky_relu)\n",
    "    with tf.variable_scope(\"layer2\"):\n",
    "        fm = dis_feature_maps[1]\n",
    "        conv2 = conv_layer(conv1,fm,5,2,True,tf.nn.leaky_relu)\n",
    "    with tf.variable_scope(\"layer3\"):\n",
    "        fm = dis_feature_maps[2]\n",
    "        conv3 = conv_layer(conv2,fm,5,2,True,tf.nn.leaky_relu)\n",
    "    with tf.variable_scope(\"readout\"):\n",
    "        conv3 = tf.reshape(conv3,[batch_size*2, -1])\n",
    "        logits = feed_forward_layer(conv3,1,False,None)\n",
    "    \n",
    "    # get trainable variables for discriminator\n",
    "    train_dis = tf.get_variable_scope().get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "##### Evaluation and training of the network #####\n",
    "with tf.variable_scope(\"evaluation\"):\n",
    "    \n",
    "    # to compute cross entropy for generator. consists of only \"1\" because this is the discriminator label for \"real\"\n",
    "    gen_labels = tf.ones((batch_size,1))\n",
    "    \n",
    "    # only the first half of the output from the discriminator concerns the pictures produced by the generator\n",
    "    # so only get first half of logits (which equals the batch_size)\n",
    "    gen_logits = logits[:batch_size]\n",
    "    \n",
    "    # for discriminator cross entropy. first half of input are fake images (\"0\"), second half real ones (\"1\")\n",
    "    dis_labels = tf.concat((tf.zeros((batch_size,1)),tf.ones((batch_size,1))),axis=0)\n",
    "    dis_logits = logits\n",
    "    \n",
    "    gen_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=gen_labels, logits=gen_logits)\n",
    "    dis_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=dis_labels, logits=dis_logits)\n",
    "    \n",
    "    # tensorboard stuff\n",
    "    tf.summary.scalar(\"generator_loss\", tf.reduce_mean(gen_loss))\n",
    "    tf.summary.scalar(\"discriminator_loss\", tf.reduce_mean(dis_loss))\n",
    "    \n",
    "    global_step = tf.get_variable(\"global_step\",[],tf.int32,trainable=False)\n",
    "    \n",
    "    # initialize optimizer\n",
    "    optimizer  = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    \n",
    "    # define training steps with respective variable lists\n",
    "    gen_step = optimizer.minimize(gen_loss, var_list=train_gen, global_step=global_step)\n",
    "    dis_step = optimizer.minimize(dis_loss, var_list=train_dis, global_step=global_step)\n",
    "    \n",
    "    summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is where we train our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T13:56:18.075671Z",
     "start_time": "2018-01-19T13:50:56.005683Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Initialising variables.\n",
      "Starting epoch 1...Finished epoch in  2m 30.52s. Estimated remaining time:  2m 30.52s\n",
      "Starting epoch 2...Finished epoch in  2m 39.61s. Estimated remaining time:  0m 0.00s\n"
     ]
    }
   ],
   "source": [
    "# HAVE ONLY MADE SMALL ADJUSTMENTS. don't think there's a point if we don't have data\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "    ## initialising directories if they do not exist\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    if not os.path.exists(summary_dir):\n",
    "        os.makedirs(summary_dir)\n",
    "    train_saver = tf.train.Saver()\n",
    "    train_writer = tf.summary.FileWriter(summary_dir, session.graph)\n",
    "    \n",
    "    ## Try to load trained data and initialise variables if there is none\n",
    "    ckpt = tf.train.latest_checkpoint(weight_dir)\n",
    "    if ckpt is None:\n",
    "        print(\"No checkpoint found. Initialising variables.\")\n",
    "        session.run(tf.global_variables_initializer())\n",
    "    else:\n",
    "        train_saver.restore(session, ckpt)\n",
    "    \n",
    "    ## Train all the epochs and save the summaries for each timestep\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        print(\"Starting epoch %d...\" %epoch, end='')\n",
    "        \n",
    "        real_data = # get batch of original recipes #mnist.get_batch(batch_size)\n",
    "        t = time.time()\n",
    "        \n",
    "        for data in real_data:\n",
    "            ## for each batch we need a new set of random vectors\n",
    "            z_vec = np.random.uniform(-1, 1, (batch_size,z_size))\n",
    "            \n",
    "            # feed data into placeholders\n",
    "            feed_dict = {input_vec: z_vec, orig_recipes: data, is_training: True}\n",
    "            \n",
    "            # let's train our network!\n",
    "            _gStep, _dStep, _summ, _step = session.run([gen_step, dis_step, summaries, global_step],\n",
    "                                                         feed_dict=feed_dict)\n",
    "            train_writer.add_summary(_summ, _step)\n",
    "            \n",
    "        t = time.time() - t\n",
    "        est = t * (epochs - epoch)\n",
    "        \n",
    "        ## This is just the time formatting. Move along.\n",
    "        m, s = divmod(t, 60)\n",
    "        e_m, e_s = divmod(est, 60)\n",
    "        \n",
    "        print((\"Finished epoch in {0: .0f}m{1: .2f}s. \"+\\\n",
    "              \"Estimated remaining time: {2: .0f}m{3: .2f}s\").format(m,s,e_m,e_s))\n",
    "        \n",
    "        train_saver.save(session, weight_dir, global_step=_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
